{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM 구현.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "0COYzrGMRba4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'{device} is available')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v99zh0nKPjL_",
        "outputId": "794591a9-fb63-4862-dc2d-36814c4b650a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 5\n",
        "num_layers = 2\n",
        "hidden_size = 8\n",
        "sequence_length=5"
      ],
      "metadata": {
        "id": "Q8ZFnaCrHRjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch import nn\n",
        "\n",
        "class lstm(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size):   # input 5,  hidden 8\n",
        "    super(lstm,self).__init__()\n",
        "\n",
        "    self.Wf=nn.Parameter(torch.randn(1, input_size))            \n",
        "    self.bf=nn.Parameter(torch.randn(1, hidden_size))            # (8,1)\n",
        "    self.Wi=nn.Parameter(torch.randn(1,input_size))             # (8,1)   \n",
        "    self.bi=nn.Parameter(torch.randn(1,hidden_size))            # (1,8)\n",
        "    self.Wc=nn.Parameter(torch.randn(1,input_size))             # (8,1)   \n",
        "    self.bc=nn.Parameter(torch.randn(1,hidden_size)) \n",
        "    self.Why=nn.Parameter(torch.randn(1,hidden_size))           # (1,8) * (8,1) = (1,1)\n",
        "    self.by=nn.Parameter(torch.randn(1,1))                       # (1,1)\n",
        "    self.Wo=nn.Parameter(torch.randn(1,input_size))\n",
        "    self.bo=nn.Parameter(torch.randn(1,hidden_size))\n",
        "\n",
        "    self.tanh=nn.Tanh()\n",
        "    self.sig=nn.Sigmoid()\n",
        "  \n",
        "  def forward(self,x,h,c):\n",
        "    f=self.tanh(self.Wf.matmul((x.matmul(h))) + self.bf)    #  (1,5) (5,8)  (1,8)\n",
        "    i=self.sig(self.Wi.matmul((x.matmul(h))) + self.bi)\n",
        "    ct=self.tanh(self.Wc.matmul((x.matmul(h))) + self.bc) \n",
        "    o=self.sig(self.Wo.matmul((x.matmul(h)))+self.bo)\n",
        "\n",
        "    c=c.mul(f)+i.mul(ct)\n",
        "    h=self.tanh(c).mul(o)\n",
        "    y=h*self.Why+self.by\n",
        "    return y, (c,h)\n",
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "  def __init__(self, backbone, input_size, hidden_size, sequence_length, num_layers, device):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = lstm(input_size, hidden_size)\n",
        "    self.fc = nn.Sequential(nn.Linear(hidden_size , 1), nn.Sigmoid())\n",
        "    self.device=device\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(x.size()[1], self.hidden_size).to(self.device) # 초기 hidden state 설정하기.\n",
        "    c0 = torch.zeros(x.size()[1], self.hidden_size).to(self.device) # 이거 추가 -> rnn과 다른점\n",
        "    out, (_,_) = self.lstm(x, h0,c0) # out: RNN의 마지막 레이어로부터 나온 output feature 를 반환한다. hn: hidden state를 반환한다.\n",
        "    out = out.reshape(out.shape[0], -1) # many to many 전략\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "model = LSTM(lstm, input_size,hidden_size,sequence_length,num_layers, device)\n",
        "                  "
      ],
      "metadata": {
        "id": "ZDXWw3ZfRcsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8iL7mnqUF2L",
        "outputId": "e3d862ce-01f6-4d17-ed49-5b9fc27c8ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): lstm(\n",
              "    (tanh): Tanh()\n",
              "    (sig): Sigmoid()\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=8, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(5,1)\n",
        "input = x\n",
        "out = model(x)\n",
        "print('input : ', input.size())\n",
        "print('output : ', out.size())"
      ],
      "metadata": {
        "id": "j1LFBk0zZyJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efa533f-2b69-4eb4-c11e-93be51c5e3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  torch.Size([5, 1])\n",
            "output :  torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f8Xpxv7ePV6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}